{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89058483-3d18-4a4a-ba46-0bdef80ce17d",
   "metadata": {},
   "source": [
    "# (1) Important Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18bbb0a-d278-46ad-849e-f7ef5ed8697a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (1.1) Tick Bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5063ca82-73e0-44ec-aba6-18b9629f4d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tick_bars(df):\n",
    "    \"\"\"\n",
    "    Generate tick bars from tick-level data.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Tick data with 'timestamp', 'price', and 'amount' columns\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Tick bars with OHLCV data\n",
    "    \"\"\"\n",
    "    \n",
    "    assert all(col in df.columns for col in ['timestamp', 'price', 'amount']), \"Missing required columns\"\n",
    "    \n",
    "    # Aggregate all ticks into a single OHLCV bar\n",
    "    bar = {\n",
    "        'timestamp': df['timestamp'].iloc[0],        # Start time\n",
    "        'open': round(df['price'].iloc[0],2),\n",
    "        'high': round(df['price'].max(),2),\n",
    "        'low': round(df['price'].min(),2),\n",
    "        'close': round(df['price'].iloc[-1],2),\n",
    "        'volume': round(df['amount'].sum(),5)\n",
    "        #\"vwap\": round((df['price'] * df['amount']).sum() / df['amount'].sum(),2)\n",
    "    }\n",
    "    \n",
    "    # Convert to DataFrame (optional)\n",
    "    bar_df = pd.DataFrame([bar])\n",
    "    \n",
    "    # Output\n",
    "    return bar_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca565943-2a55-424e-a5d7-e3ea2aa5a7a6",
   "metadata": {},
   "source": [
    "## (1.2) Calculate the properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "3c1b709b-c66f-4a0c-8a68-f26689c0a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class predictors():\n",
    "\n",
    "    def Relative_strength_index(self):\n",
    "        n = 14\n",
    "        \n",
    "        average_gain= np.full((1,n-1),np.nan)\n",
    "        average_loss= np.full((1,n-1),np.nan)\n",
    "    \n",
    "        for t in range(n,len(self.changes)+1):\n",
    "            interval = np.array(self.changes[t-n:t])\n",
    "    \n",
    "            gain = np.array([])\n",
    "            loss = np.array([])\n",
    "    \n",
    "            for i in interval:\n",
    "                if (i> 0):\n",
    "                    gain = np.append(gain,i)\n",
    "                elif(i< 0): \n",
    "                    loss = np.append(loss,i)\n",
    "            \n",
    "            # average gain\n",
    "            try:\n",
    "                average_gain = np.append(average_gain,mean(gain))\n",
    "            except:\n",
    "                average_gain = np.append(average_gain,1)\n",
    "    \n",
    "            # average loss\n",
    "            try:\n",
    "                average_loss = np.append(average_loss,mean(abs(loss)))\n",
    "            except:\n",
    "                average_loss = np.append(average_loss,1) \n",
    "    \n",
    "        RS = np.array(average_gain/average_loss)\n",
    "        RSI = np.array(100 - (100/(1+RS)))\n",
    "\n",
    "        res = np.append(np.full((1,1),np.nan),RSI)\n",
    "        return(res)\n",
    "\n",
    "    def Average_true_range(self):\n",
    "\n",
    "        # True Range components\n",
    "        high_low = self.data['high'] - self.data['low']\n",
    "        high_close_prev = (self.data['high'] - self.data['close'].shift(1)).abs()\n",
    "        low_close_prev = (self.data['low'] - self.data['close'].shift(1)).abs()\n",
    "        \n",
    "        # True Range\n",
    "        tr = pd.concat([high_low, high_close_prev, low_close_prev], axis=1).max(axis=1)\n",
    "        \n",
    "        # ATR (simple moving average of TR)\n",
    "        atr = tr.rolling(window=14, min_periods=1).mean()\n",
    "        \n",
    "        return atr\n",
    "    \n",
    "    def Average_directional_index(self):\n",
    "        \n",
    "         # 1. Calculate True Range (TR)\n",
    "        high_low = self.data['high'] - self.data['low']\n",
    "        high_close_prev = (self.data['high'] - self.data['close'].shift(1)).abs()\n",
    "        low_close_prev = (self.data['low'] - self.data['close'].shift(1)).abs()\n",
    "        tr = pd.concat([high_low, high_close_prev, low_close_prev], axis=1).max(axis=1)\n",
    "    \n",
    "        # 2. Calculate directional movements\n",
    "        plus_dm = self.data['high'] - self.data['high'].shift(1)\n",
    "        minus_dm = self.data['low'].shift(1) - self.data['low']\n",
    "    \n",
    "        plus_dm = np.where((plus_dm > minus_dm) & (plus_dm > 0), plus_dm, 0.0)\n",
    "        minus_dm = np.where((minus_dm > plus_dm) & (minus_dm > 0), minus_dm, 0.0)\n",
    "    \n",
    "        # 3. Smooth TR, +DM, -DM (Wilder's smoothing)\n",
    "        tr_smooth = pd.Series(tr).rolling(window=14).sum()\n",
    "        plus_dm_smooth = pd.Series(plus_dm).rolling(window=14).sum()\n",
    "        minus_dm_smooth = pd.Series(minus_dm).rolling(window=14).sum()\n",
    "    \n",
    "        # 4. Calculate +DI and -DI\n",
    "        plus_di = 100 * (plus_dm_smooth / tr_smooth)\n",
    "        minus_di = 100 * (minus_dm_smooth / tr_smooth)\n",
    "    \n",
    "        # 5. Calculate DX\n",
    "        dx = (abs(plus_di - minus_di) / (plus_di + minus_di)) * 100\n",
    "    \n",
    "        # 6. ADX = smoothed DX\n",
    "        adx = dx.rolling(window=14).mean()\n",
    "    \n",
    "        # Return as DataFrame\n",
    "        df_out = pd.DataFrame()\n",
    "        df_out['+DI'] = plus_di\n",
    "        df_out['-DI'] = minus_di\n",
    "        df_out['ADX'] = adx\n",
    "    \n",
    "        return df_out\n",
    "    \n",
    "    def __init__(self,data):\n",
    "\n",
    "        self.data = data\n",
    "        \n",
    "        #### changes from price #####\n",
    "        self.changes = np.array([])\n",
    "        close = np.array(data[\"close\"])\n",
    "        for t in range(1,len(close)):\n",
    "            self.changes = np.append(self.changes,(close[t]-close[t-1]))\n",
    "\n",
    "        ### moving averages ###\n",
    "        SMA_9 = np.array(data[\"close\"].rolling(window=9).mean())\n",
    "        SMA_21 = np.array(data[\"close\"].rolling(window=21).mean())\n",
    "        EMA_9 = np.array(data[\"close\"].ewm(span=9, adjust=False, min_periods=9).mean())\n",
    "        EMA_21 = np.array(data[\"close\"].ewm(span=21, adjust=False, min_periods=9).mean())\n",
    "\n",
    "        ### Relative Strength Index (RSI) (14) ###\n",
    "        RSI = self.Relative_strength_index()\n",
    "\n",
    "        ### ATR (Average True Range) (14) ###\n",
    "        ATR = self.Average_true_range()\n",
    "        \n",
    "        ### ADX (Average Directional Index) (14) ###\n",
    "        ADX = self.Average_directional_index()\n",
    "        \n",
    "        ### predictors ###\n",
    "        # \"MiddleBand\":BD[\"MiddleBand\"],\"UpperBand\":BD[\"UpperBand\"],\"LowerBand\":BD[\"LowerBand\"],\"MACD\":MACD,\"ATR\":ATR,\"ADX\":ADX, \n",
    "        self.predictors = {\"timestamp\":self.data[\"timestamp\"],\"SMA 9\":np.round(SMA_9,2),\"SMA 21\":np.round(SMA_21,2),\"EMA 9\":np.round(EMA_9,2),\"EMA 21\":np.round(EMA_21,2),\n",
    "                             \"RSI\":np.round(RSI,2),\"ATR\":np.round(ATR,2),\"+DI\":np.round(ADX[\"+DI\"],2),\"-DI\":np.round(ADX[\"-DI\"],2),\"ADX\":np.round(ADX[\"ADX\"],2)}\n",
    "        \n",
    "    def get_predictors(self):\n",
    "        return(self.predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360c764a-209d-472c-91da-d80897238751",
   "metadata": {},
   "source": [
    "# (2) Data Preprocessing / Cleaning\n",
    "This code is used to:\n",
    "- Data Loading\n",
    "- Data Preprocessing / Cleaning:\n",
    "    - Calculate standard bars (Tick bars), based in minute statistics for the thresholds, calculate exponential the moving averages for tresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "b528d1b5-310f-47a2-a3a2-e4edef1e8e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MatchTrades 2025-08-18 23:37:27 to 2025-08-21 13:36:43.json']\n"
     ]
    }
   ],
   "source": [
    "files_tickdata = os.listdir(\"Data\")\n",
    "files_tickdata = [f for f in files_tickdata if f != '.ipynb_checkpoints']\n",
    "print(files_tickdata[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0f4987bc-8ea2-4957-aa93-119fe5c2c33b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MatchTrades 2025-08-18 23:37:27 to 2025-08-21 13:36:43.json']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from bson import json_util\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import ipaddress\n",
    "import pymongo\n",
    "from datetime import datetime, timedelta\n",
    "from statistics import mean, stdev\n",
    "\n",
    "## --------------------------------------------------------- ##\n",
    "##  (1)                 get all the files in the folder      ##\n",
    "## --------------------------------------------------------- ##\n",
    "\n",
    "files_tickdata = os.listdir(\"Data\")\n",
    "files_tickdata = [f for f in files_tickdata if f != '.ipynb_checkpoints']\n",
    "files_tickdata = (files_tickdata[2:])\n",
    "print(files_tickdata)\n",
    "#print(\"\\n\")\n",
    "\n",
    "## --------------------------------------------------------- ##\n",
    "##  End (1)                                                  ##\n",
    "## --------------------------------------------------------- ##\n",
    "\n",
    "for file in files_tickdata:\n",
    "\n",
    "    ## ----------------------------------------------------------- ##\n",
    "    ##  (2)  Open files and Enforce Column Types through pandas    ##\n",
    "    ## ----------------------------------------------------------- ##\n",
    "    \n",
    "    # Load the data\n",
    "    # amount = float32\n",
    "    # price = float64\n",
    "    \n",
    "    with open(\"Data/\"+file) as f:\n",
    "        MatchTrades_tickdata_df = pd.read_json(f).astype({\"amount\":\"float32\",\"price\":\"float64\"})\n",
    "        MatchTrades_tickdata_df[\"timestamp\"] = pd.to_datetime(MatchTrades_tickdata_df[\"timestamp\"], unit='ms')\n",
    "\n",
    "    #MatchTrades_tickdata_df = MatchTrades_tickdata_df.iloc[0:1000][[\"timestamp\",\"amount\",\"price\"]]\n",
    "    #print(MatchTrades_tickdata_df)\n",
    "    \n",
    "    ## ----------------------------------------------------------- ##\n",
    "    ##     End (2)                                                 ##\n",
    "    ## ----------------------------------------------------------- ##\n",
    "    \n",
    "    ## ------------------------------------------------- ##\n",
    "    ##  (3)  Calculate standard bars (Tick bars)         ##\n",
    "    ## ------------------------------------------------- ##\n",
    "    \n",
    "    ## Convert timestamp from milliseconds to datetime\n",
    "    df = MatchTrades_tickdata_df\n",
    "    \n",
    "    # create the minute aggregated data\n",
    "    # volume = float32\n",
    "    # n_ticks = int16\n",
    "    \n",
    "    minute_tick_bars = (\n",
    "        df\n",
    "        .set_index('timestamp')\n",
    "        .resample('1min')\n",
    "        .agg({'amount': 'sum'})\n",
    "        .rename(columns={'amount': 'volume'})\n",
    "        .assign(n_ticks=lambda x: df.set_index('timestamp').resample('1min').size())\n",
    "        .astype({\n",
    "            \"volume\": \"float32\",\n",
    "            \"n_ticks\": \"int16\"\n",
    "        })\n",
    "    ).reset_index()\n",
    "    \n",
    "    minute_tick_bars[\"timestamp\"] = pd.to_datetime(minute_tick_bars[\"timestamp\"], unit='s')\n",
    "    \n",
    "    ## calculate exponential the moving averages for tresholds\n",
    "    # volume_per_min = float32\n",
    "    # n_ticks_per_min = int16\n",
    "    \n",
    "    volume_per_min = (minute_tick_bars[\"volume\"]).ewm(span=60,adjust=False).mean().round(5).astype(\"float32\")\n",
    "    n_ticks_per_min = (minute_tick_bars[\"n_ticks\"]).ewm(span=60,adjust=False).mean().round(0).astype(\"int16\")\n",
    "    \n",
    "    ## minute data for creating the tick bars\n",
    "    df_ema = pd.DataFrame({\n",
    "        \"timestamp\": minute_tick_bars[\"timestamp\"],\n",
    "        \"volume_per_min\": volume_per_min,\n",
    "        \"n_ticks_per_min\": n_ticks_per_min\n",
    "    })\n",
    "    #print(df_ema)\n",
    "    \n",
    "    ## create dataframes for creating Tick  bars \n",
    "    Tickdata_MatchTrades_TB = pd.DataFrame() # Tick data for the Tick Bar (TB)\n",
    "    TickBars_df = pd.DataFrame()\n",
    "    \n",
    "    for row in MatchTrades_tickdata_df.itertuples(index=True, name=\"Trade\"):\n",
    "    \n",
    "        timestamp = row.timestamp\n",
    "        \n",
    "        try:\n",
    "            if timestamp.replace(second=0, microsecond=0) == df_ema.iloc[0][\"timestamp\"]:\n",
    "                n_ticks_per_min = df_ema.iloc[0][\"n_ticks_per_min\"]\n",
    "                df_ema = df_ema.drop(0).reset_index(drop=True)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        Tickdata_MatchTrades_TB = pd.concat([Tickdata_MatchTrades_TB, pd.DataFrame([row])], ignore_index=True)\n",
    "        \n",
    "        if len(Tickdata_MatchTrades_TB) >= int(n_ticks_per_min/5):\n",
    "            TickBar = generate_tick_bars(Tickdata_MatchTrades_TB)\n",
    "            TickBar[\"ticks\"] = len(Tickdata_MatchTrades_TB)\n",
    "            TickBars_df = pd.concat([TickBars_df, TickBar], ignore_index=True)\n",
    "            Tickdata_MatchTrades_TB = pd.DataFrame()\n",
    "\n",
    "    TickBars_df[\"ticks\"] = TickBars_df[\"volume\"].astype(\"int16\")\n",
    "    TickBars_df[\"timestamp\"] =  TickBars_df[\"timestamp\"].apply(lambda x: int(x.timestamp()* 1000))\n",
    "    \n",
    "    ## ------------------------------------------------- ##\n",
    "    ##  (3)  End                                         ##\n",
    "    ## ------------------------------------------------- ##\n",
    "    \n",
    "    ## ------------------------------------------------- ##\n",
    "    ##  (4)  Save data                                   ##\n",
    "    ## ------------------------------------------------- ##\n",
    "    \n",
    "    raw_data = TickBars_df.to_dict(orient=\"records\")\n",
    "    json_raw_data = json_util.dumps(raw_data)\n",
    "    \n",
    "    end_ts = float(TickBars_df.iloc[0][\"timestamp\"])/1000\n",
    "    start_ts = float(TickBars_df.iloc[-1][\"timestamp\"])/1000\n",
    "    \n",
    "    with open(\"TickBars/\"+\"TickBars_df \"+ datetime.fromtimestamp(end_ts).strftime(\"%Y-%m-%d %H:%M:%S\") + \" to \" + datetime.fromtimestamp(start_ts).strftime(\"%Y-%m-%d %H:%M:%S\") +\".json\", \"w\") as f:\n",
    "                f.write(json_raw_data)\n",
    "    \n",
    "    ## ------------------------------------------------- ##\n",
    "    ##  (4)  End                                         ##\n",
    "    ## ------------------------------------------------- ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a9189b-5e97-414c-aeb7-12621c840a7b",
   "metadata": {},
   "source": [
    "# (3) Feature Preparation\n",
    "\n",
    "## This code is used to:\n",
    "- Calculate the properties from Tick bars:\n",
    "    - Relative strength index (RSI).\n",
    "    - Average true range (ATR).\n",
    "    - Average directional index (ADI).\n",
    "    - Simple moving averages (SMA).\n",
    "    - Exponential moving averages (EMA).\n",
    "- Create signals for entry and exiting the market:\n",
    "    - Simple moving averages (SMA) (9,21).\n",
    "    - Exponential moving averages (EMA) (9,21).\n",
    "    - Relative strength index (RSI) (30,70)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "e95d0e7e-c13b-4028-b9b9-60f9cd7f9ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TickBars_df 2025-08-18 23:37:27 to 2025-08-21 13:36:28.json']\n"
     ]
    }
   ],
   "source": [
    "files_tickbars = os.listdir(\"TickBars\")\n",
    "files_tickbars = [f for f in files_tickbars if f != '.ipynb_checkpoints']\n",
    "files_tickbars = files_tickbars[:1]\n",
    "print(files_tickbars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "9c7387de-c90d-468e-a193-ebd0f6ab7c8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1531106/2515657750.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signal_df['Signal SMA'] = ((signal_df['SMA 9'] > signal_df['SMA 21']) &\n",
      "/tmp/ipykernel_1531106/2515657750.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signal_df['Signal SMA'] -= ((signal_df['SMA 9'] < signal_df['SMA 21']) &\n",
      "/tmp/ipykernel_1531106/2515657750.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signal_df.loc[\n",
      "/tmp/ipykernel_1531106/2515657750.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signal_df[\"Signal EMA\"] = signal_df[\"Signal EMA\"].fillna(0).astype(int)\n",
      "/tmp/ipykernel_1531106/2515657750.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  signal_df['Signal RSI'] = np.where(signal_df['RSI'] < 30, 1, np.where(signal_df['RSI'] > 70, -1, 0))\n"
     ]
    }
   ],
   "source": [
    "for file in files_tickbars:\n",
    "\n",
    "    # Load the data\n",
    "    with open(\"TickBars/\"+file) as f:\n",
    "        TickBars_df = pd.read_json(f)\n",
    "        TickBars_df[\"timestamp\"] = pd.to_datetime(TickBars_df[\"timestamp\"], unit='ms')\n",
    "        \n",
    "    # calculating the predictors for \n",
    "    calc_pred = predictors(TickBars_df)\n",
    "    pred_df = pd.DataFrame(calc_pred.get_predictors())\n",
    "    pred_df[\"timestamp\"] =  pred_df[\"timestamp\"].apply(lambda x: int(x.timestamp()* 1000))\n",
    "    \n",
    "    ##########################################\n",
    "    ##              Save data               ##\n",
    "    \n",
    "    raw_data = pred_df.to_dict(orient=\"records\")\n",
    "    json_raw_data = json_util.dumps(raw_data)\n",
    "    \n",
    "    end_ts = float(pred_df.iloc[0][\"timestamp\"])/1000\n",
    "    start_ts = float(pred_df.iloc[-1][\"timestamp\"])/1000\n",
    "    \n",
    "    with open(\"Features/\"+\"Features df \"+ datetime.fromtimestamp(end_ts).strftime(\"%Y-%m-%d %H:%M:%S\") + \" to \" + datetime.fromtimestamp(start_ts).strftime(\"%Y-%m-%d %H:%M:%S\") +\".json\", \"w\") as f:\n",
    "                f.write(json_raw_data)\n",
    "    \n",
    "    ##########################################\n",
    "    ##########################################\n",
    "    \n",
    "    # removing the firsts rows with Nan values\n",
    "    signal_df = pred_df.iloc[26:]\n",
    "\n",
    "    # -------------------------------------------------------------------------------- #\n",
    "    #             creating a signal to buy and sell from the predictors                #\n",
    "    # -------------------------------------------------------------------------------- #\n",
    "    \n",
    "\n",
    "    # SMA 9,21 signals\n",
    "    \n",
    "    # 1 = SMA 9 crosses above SMA 21 (bullish)\n",
    "    signal_df['Signal SMA'] = ((signal_df['SMA 9'] > signal_df['SMA 21']) & \n",
    "                   (signal_df['SMA 9'].shift(1) <= signal_df['SMA 21'].shift(1))).astype(int)\n",
    "    \n",
    "    # -1 = SMA 9 crosses below SMA 21 (bearish)\n",
    "    signal_df['Signal SMA'] -= ((signal_df['SMA 9'] < signal_df['SMA 21']) & \n",
    "                    (signal_df['SMA 9'].shift(1) >= signal_df['SMA 21'].shift(1))).astype(int)\n",
    "    \n",
    "    # Bullish crossover: EMA 9 crosses ABOVE EMA 21\n",
    "    signal_df.loc[\n",
    "        (signal_df['EMA 9'] > signal_df['EMA 21']) & \n",
    "        (signal_df['EMA 9'].shift(1) <= signal_df['EMA 21'].shift(1)),\n",
    "        \"Signal EMA\"\n",
    "    ] = 1\n",
    "    \n",
    "    # Bearish crossover: EMA 9 crosses BELOW EMA 21\n",
    "    signal_df.loc[\n",
    "        (signal_df['EMA 9'] < signal_df['EMA 21']) & \n",
    "        (signal_df['EMA 9'].shift(1) >= signal_df['EMA 21'].shift(1)),\n",
    "        \"Signal EMA\"\n",
    "    ] = -1\n",
    "    \n",
    "    # Fill the rest with 0 (no signal)\n",
    "    signal_df[\"Signal EMA\"] = signal_df[\"Signal EMA\"].fillna(0).astype(int)\n",
    "    \n",
    "    # Generate signals for RSI\n",
    "    signal_df['Signal RSI'] = np.where(signal_df['RSI'] < 30, 1, np.where(signal_df['RSI'] > 70, -1, 0))\n",
    "    \n",
    "    ##########################################\n",
    "    ##          Save signals data           ##\n",
    "    \n",
    "    raw_data = signal_df.to_dict(orient=\"records\")\n",
    "    json_raw_data = json_util.dumps(raw_data)\n",
    "    \n",
    "    end_ts = float(signal_df.iloc[0][\"timestamp\"])/1000\n",
    "    start_ts = float(signal_df.iloc[-1][\"timestamp\"])/1000\n",
    "    \n",
    "    with open(\"Signals/\"+\"Signals_df \"+ datetime.fromtimestamp(end_ts).strftime(\"%Y-%m-%d %H:%M:%S\") + \" to \" + datetime.fromtimestamp(start_ts).strftime(\"%Y-%m-%d %H:%M:%S\") +\".json\", \"w\") as f:\n",
    "                f.write(json_raw_data)\n",
    "\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "    \n",
    "    # -------------------------------------------------------------------------------- #\n",
    "    #                                                                                  #\n",
    "    # -------------------------------------------------------------------------------- #\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "610ec25d-5a79-44a5-82b6-4a1bdff393b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred_df.iloc[26][\"ADX\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
