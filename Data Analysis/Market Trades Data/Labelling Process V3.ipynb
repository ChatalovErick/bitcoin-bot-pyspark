{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "526e9036-44ac-42f9-8d37-c7ce5f38e77f",
   "metadata": {},
   "source": [
    "# (4) Labelling \n",
    "\n",
    "The labeling process will be made for the SMA 21,9 entry points. This labelling process uses the limit barriers that are not used in the labeling V1, the vertical barrier will be determined from asimple Bayesian waiting-time model for trade durations using an exponential distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b5b663-11a9-4b64-90bf-e686e46477f7",
   "metadata": {},
   "source": [
    "## (4.1) Triple Barrier Method\n",
    "\n",
    "using the SMA , EMA and RSI market signals for entering and exiting the market. this returns all the data the happened during the labelling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e24e5f7c-0a66-409a-86a7-ee3932668861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class triple_barrier_method():\n",
    "\n",
    "    \"\"\"\n",
    "    ptSl[0]: The factor that multiplies trgt to set the width of the upper barrier.\n",
    "    If 0, there will not be an upper barrier.\n",
    "    ptSl[1]: The factor that multiplies trgt to set the width of the lower barrier.\n",
    "    If 0, there will not be a lower barrier.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,trade,qty,ptSl,signal):\n",
    "        self.trades = []\n",
    "        self.trades.append(trade)\n",
    "        self.qty = qty\n",
    "        \n",
    "        self.entry_signal = signal.to_dict()\n",
    "        self.upper_barrier = ptSl[0]\n",
    "        self.lower_barrier = ptSl[1]\n",
    "        self.time_barrier = ptSl[2]\n",
    "        \n",
    "    def add_trade(self,tickdata):\n",
    "        self.trades.append(tickdata)\n",
    "    \n",
    "    def get_trade_list(self):\n",
    "        return self.trades\n",
    "\n",
    "    def get_upper_barrier(self):\n",
    "        return self.upper_barrier\n",
    "\n",
    "    def get_lower_barrier(self):\n",
    "        return self.lower_barrier\n",
    "\n",
    "    def get_time_barrier(self):\n",
    "        return self.time_barrier\n",
    "    \n",
    "    def end_barrier(self,signal):\n",
    "        tickdata = pd.DataFrame(self.trades)\n",
    "        self.exit_signal = signal.to_dict()\n",
    "        \n",
    "        ## calculate the change form first and last price\n",
    "        if len(tickdata) < 2:\n",
    "            return 0.0\n",
    "            \n",
    "        first =  (tickdata.iloc[0][\"price\"])\n",
    "        last = (tickdata.iloc[-1][\"price\"])\n",
    "        change = (last - first) / first\n",
    "        \n",
    "        entry_dict = {\"timestamp\":tickdata.iloc[0][\"timestamp\"],\"price\":first}\n",
    "        out_entry = entry_dict | self.entry_signal\n",
    "    \n",
    "        exit_dict = {\"timestamp\":tickdata.iloc[-1][\"timestamp\"],\"price\":last}\n",
    "        out_exit = exit_dict | self.exit_signal\n",
    "\n",
    "        waiting_time = (tickdata.iloc[-1][\"timestamp\"]).timestamp() - (tickdata.iloc[0][\"timestamp\"]).timestamp() \n",
    "        \n",
    "        out = {\"entry\": out_entry, \"exit\": out_exit, \"qty\":self.qty, \"change\":change,\"upper barrier\": self.upper_barrier,\"lower barrier\":self.lower_barrier,\"trade duration\":waiting_time}\n",
    "        \n",
    "        self.trades = []\n",
    "        return(pd.DataFrame([out]))\n",
    "\n",
    "    def remove_all_data(self):\n",
    "        self.trades = []\n",
    "        self.entry_signal = None\n",
    "        self.upper_barrier = None\n",
    "        self.lower_barrier = None\n",
    "        self.time_barrier = None\n",
    "        self.exit_signal = None\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1a5f60-c33b-4a12-9d76-da4b006704c5",
   "metadata": {},
   "source": [
    "## (4.2) Bayesian Modeling of Trade Waiting Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "2ccd687e-6938-4b25-9e9f-660b7072bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma\n",
    "\n",
    "class calculate_trade_wait_time():\n",
    "\n",
    "    ## update priors on sucessful trades ##\n",
    "    ## the model is a gamma posterior on a exponential likelihood and a gamma prior\n",
    "    \n",
    "    def __init__(self,priors):\n",
    "        # save priors\n",
    "        self.priors = priors\n",
    "        # variables that will be updated\n",
    "        self.alpha = priors[0] \n",
    "        self.beta = priors[1]\n",
    "\n",
    "    def update_parameters(self,trade_time):\n",
    "        self.alpha += 1\n",
    "        self.beta += trade_time\n",
    "        \n",
    "    def get_posteriors(self):\n",
    "        # output: [alpha,beta]\n",
    "        return [self.alpha,self.beta]\n",
    "\n",
    "    def sample_time(self):\n",
    "        return gamma.rvs(a=self.alpha, scale=1/self.beta, size=1)[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2032a4f-39f6-47e0-8721-adcc986d5950",
   "metadata": {},
   "source": [
    "# (5) Parallel optimization (Labelling process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633e8e38-13ab-4ece-b146-249a137b2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from itertools import combinations\n",
    "from itertools import repeat\n",
    "import os\n",
    "\n",
    "def labelling_process_function(bartype,signal,data,MatchTrades_tickdata):\n",
    "\n",
    "    ## Important variables to run the labelling process ##\n",
    "    total_positions = list(data.values())[2]\n",
    "    signals_df = list(data.values())[0]\n",
    "    stats_df = list(data.values())[1]\n",
    "    positions = pd.DataFrame()\n",
    "\n",
    "    time_barrier = list(data.values())[3]\n",
    "    open_position = False\n",
    "    ## ------------------------------------------------ ##\n",
    "    \n",
    "    for Matchtrade in MatchTrades_tickdata.itertuples(index=True, name=\"Trade\"):    \n",
    "\n",
    "        timestamp = Matchtrade.timestamp\n",
    "        # ----------------------------- #\n",
    "        try:\n",
    "            if (tbm.get_trade_list() != []):\n",
    "                tbm.add_trade(Matchtrade)\n",
    "        except: \n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            if timestamp == signals_df.iloc[0][\"timestamp\"]:\n",
    "                # signals\n",
    "                signal_x = signals_df.iloc[0]\n",
    "                signals_df = signals_df.iloc[1:].reset_index(drop=True)\n",
    "                # stasts \n",
    "                stats_x = stats_df.iloc[0]\n",
    "                stats_df = stats_df.iloc[1:].reset_index(drop=True)\n",
    "            # ----------------------------- #\n",
    "            #       Buying strategy         # \n",
    "                try:  \n",
    "                    # start position\n",
    "                    if (((signal_x[1:] == 1).all()) and (open_position == False)):\n",
    "\n",
    "                        open_position = True\n",
    "                        qty = 1\n",
    "                        \n",
    "                        # profit-taking, stop-loss and time limits \n",
    "                        barriers = [round(Matchtrade.price + 0.05*Matchtrade.price,2),round(Matchtrade.price - 0.02*Matchtrade.price,2), round((Matchtrade.timestamp).timestamp(),3) + round(time_barrier.sample_time(),3)*60]\n",
    "                        signal_trade = pd.concat([signal_x[1:], stats_x[1:]],axis=0)                        \n",
    "                        tbm = triple_barrier_method(Matchtrade,qty=qty,ptSl = barriers,signal=signal_trade)\n",
    "                except:\n",
    "                    pass\n",
    "            # ----------------------------- #\n",
    "            # ----------------------------- #\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # ----------------------------------------------------- # \n",
    "        # ----------------------------------------------------- #        \n",
    "        try:\n",
    "            \n",
    "            if ((tbm.get_upper_barrier() <= Matchtrade.price) or (tbm.get_lower_barrier() >= Matchtrade.price) or (round(tbm.get_time_barrier(),3) <= timestamp.timestamp())\n",
    "               or ((signal_x[1:] == -1).all())):\n",
    "\n",
    "                open_position = False\n",
    "        \n",
    "                signal_trade = pd.concat([signal_x[1:], stats_x[1:]],axis=0)                        \n",
    "                result = tbm.end_barrier(signal=signal_trade)\n",
    "                #result[\"change\"] = result[\"change\"] - 0.02 \n",
    "                \n",
    "                if result.iloc[0][\"change\"] > 0.002:\n",
    "                    time_barrier.update_parameters(result.iloc[0][\"trade duration\"])\n",
    "\n",
    "                positions = pd.concat([positions, result], ignore_index=True)\n",
    "                tbm.remove_all_data()\n",
    "        except:\n",
    "            pass\n",
    "        # ----------------------------------------------------- # \n",
    "        # ----------------------------------------------------- #  \n",
    "\n",
    "    # save the positions from all the different files\n",
    "    total_positions =  pd.concat([total_positions, positions], ignore_index=True)\n",
    "    print(total_positions)\n",
    "    \n",
    "    ##########################################\n",
    "    ##          Save signals data           ##\n",
    "    \n",
    "    raw_data = total_positions.to_dict(orient=\"records\")\n",
    "    json_raw_data = json_util.dumps(raw_data)\n",
    "    \n",
    "    with open(f\"Positions/{bartype}/{signal}.json\", \"w\") as f:\n",
    "                f.write(json_raw_data)\n",
    "\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "\n",
    "    return({\"variable\":signal,\"total_positions\":total_positions,\"time_barrier_post\":time_barrier.get_posteriors()})\n",
    "    \n",
    "def wrapper(args):\n",
    "    return labelling_process_function(*args)\n",
    "\n",
    "class Labelling_Process():\n",
    "    \n",
    "    ## Documentation ##\n",
    "    # This class receives two dataframes:\n",
    "    # - data: a dataframe that contain all the timestamp and all the stats used to calculate the signal\n",
    "    # - signals: a dataframe that contain rows with 1, -1 and 0 for entry and exiting of positions, \n",
    "    # signals are created from the statistics.\n",
    " \n",
    "    # This function is used to test multiple strategies at the same time, and make combinations of diferent signals to find\n",
    "    # entry and exiting points for market research. \n",
    "\n",
    "    def update_variables(self,variable,total_positions,time_barrier_params):\n",
    "        \n",
    "        self.variables_simulation[variable][\"total_positions\"] = total_positions\n",
    "        self.variables_simulation[variable][\"time_barrier\"] = calculate_trade_wait_time(priors=time_barrier_params)\n",
    "\n",
    "    def return_results(self):\n",
    "\n",
    "        return (self.variables_simulation)\n",
    "    \n",
    "    def __init__(self,bartype,stats_data,signals,complementary_stats,MatchTrades_tickdata,parallel_processing = False):\n",
    "\n",
    "        # ----------------------------------------------------- #\n",
    "        #    (1)       Test for variable types                  #\n",
    "        \n",
    "        # receive three dataframes, one with the statistics and another with the signals for market positions.\n",
    "        # 1. stats_data: statistics made for creating the signals.\n",
    "        # 2. signals: a dataframe containing the entry and exiting signals based on the the statistics data.\n",
    "        # 3. complementary_stats: a list of names of the statistics that are used inside of the model and have nothing to do with\n",
    "        # signals created.\n",
    "        \n",
    "        # test that the data types of the variables of signals are int16\n",
    "        # 1. Check first column type\n",
    "        first_col = signals.columns[0]\n",
    "        if not np.issubdtype(signals[first_col].dtype, np.datetime64):\n",
    "            raise TypeError(f\"First column '{first_col}' must be datetime64[ns], got {signals[first_col].dtype}\")\n",
    "        \n",
    "        # 2. Check other columns type\n",
    "        for col in signals.columns[1:]:\n",
    "            if signals[col].dtype != \"int16\":\n",
    "                raise TypeError(f\"Column '{col}' must be float32, got {signals[col].dtype}\")\n",
    "\n",
    "        # test if the variables of data are float 32 and the variable timestamp is a timestamp type.\n",
    "        first_col = stats_data.columns[0]\n",
    "        if not np.issubdtype(stats_data[first_col].dtype, np.datetime64):\n",
    "            raise TypeError(f\"First column '{first_col}' must be datetime64[ns], got {stats_data[first_col].dtype}\")\n",
    "                    \n",
    "        self.stats_data = stats_data\n",
    "        self.signals = signals\n",
    "        self.MatchTrades_tickdata = MatchTrades_tickdata\n",
    "        \n",
    "        #   (1) End                                             #\n",
    "        # ----------------------------------------------------- #\n",
    "\n",
    "        # --------------------------------------------------------------------- #\n",
    "        # (2) Set up variables for the individual and combination of variables  #\n",
    "\n",
    "        # variables for Initialization of the simulation #\n",
    "        self.variables_simulation = {}\n",
    "        \n",
    "        self.df_variables = []\n",
    "        # make combination of the column names in order to meke the variables\n",
    "        for n in range(1,len(signals.columns[1:])+1):\n",
    "            combos = list(combinations(signals.columns[1:], r=n))\n",
    "\n",
    "            for combo in combos:\n",
    "                self.df_variables.append(combo)\n",
    "                \n",
    "                if len(combo) == 1:\n",
    "                    # single element → replace spaces with underscore\n",
    "                    variable = combo[0].replace(\" \", \"_\")\n",
    "                else:\n",
    "                    # multiple elements → keep common prefix once\n",
    "                    prefix = combo[0].split()[0]  # e.g., \"Signal\"\n",
    "                    suffixes = [s.split()[-1] for s in combo]\n",
    "                    variable = prefix + \"_\" + \"_\".join(suffixes)\n",
    "\n",
    "                # ----------------------------------------------------- #\n",
    "                # list of column names from data that match the signals\n",
    "                # Extract individual signals from variable\n",
    "                if variable.startswith(\"Signal_\"):\n",
    "                    parts = variable.replace(\"Signal_\", \"\").split(\"_\")\n",
    "                else:\n",
    "                    parts = variable.split(\"_\")\n",
    "                \n",
    "                # Map signals to actual df columns\n",
    "                matched_cols = []\n",
    "                for part in parts:\n",
    "                    for col in stats_data.columns:\n",
    "                        if col.startswith(part):\n",
    "                            matched_cols.append(col)\n",
    "\n",
    "                self.variables_simulation[variable] = {\n",
    "                    \"signals_data\": signals[[\"timestamp\"]+list(combo)],\n",
    "                    \"stats_data\": stats_data[[\"timestamp\"]+matched_cols+complementary_stats],\n",
    "                    \"total_positions\": pd.DataFrame(),\n",
    "                    \"time_barrier\": calculate_trade_wait_time(priors=[60,1]),\n",
    "                }\n",
    "\n",
    "                # ----------------------------------------------------- #\n",
    "                \n",
    "        # (2) End                                                               #\n",
    "        # --------------------------------------------------------------------- #\n",
    "\n",
    "        # --------------------------------------------------------------------- #\n",
    "        # (3) Parallel processing \n",
    "\n",
    "        # Bundle into tuples\n",
    "        input_parallel_data = list(zip(repeat(bartype),self.variables_simulation.keys(), self.variables_simulation.values(),repeat(self.MatchTrades_tickdata)))\n",
    "        \n",
    "        if (parallel_processing == True):\n",
    "             \n",
    "            with ProcessPoolExecutor(max_workers=3) as executor:\n",
    "                results = list(executor.map(wrapper,input_parallel_data))\n",
    "\n",
    "        ## update the class variables ##\n",
    "        for value in results:\n",
    "            self.update_variables(value[\"variable\"],value[\"total_positions\"],value[\"time_barrier_post\"])\n",
    "            \n",
    "        # (3) End                                                               #\n",
    "        # --------------------------------------------------------------------- #\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc9b51a-7fc2-4894-a481-3c515aeb2f12",
   "metadata": {},
   "source": [
    "# (6) Main code (TickBars, VolumeBars VolumeImbalanceBars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "281df3c2-df39-44f0-9a6a-1cbf279e1848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TickBars\n",
      "VolumeBars\n",
      "VolumeImbalanceBars\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "folders = [\"TickBars\",\"VolumeBars\",\"VolumeImbalanceBars\"]\n",
    "\n",
    "# sort data files from the latest to newest \n",
    "path = Path(\"Data\")\n",
    "files_sorted = sorted(\n",
    "    path.iterdir(),\n",
    "    key=lambda f: f.stat().st_mtime, \n",
    "    reverse=False                      \n",
    ")\n",
    "\n",
    "data_files = []\n",
    "\n",
    "for f in files_sorted:\n",
    "    data_files.append(f.name)\n",
    "    \n",
    "data_files = [f for f in data_files if f != '.ipynb_checkpoints']\n",
    "\n",
    "### resulf from all the files ###\n",
    "\n",
    "for folder in folders:\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    print(folder)\n",
    "\n",
    "    path = Path(f\"Signals/{folder} Signals\")\n",
    "    signals_files_sorted = sorted(\n",
    "        path.iterdir(),\n",
    "        key=lambda f: f.stat().st_mtime, \n",
    "        reverse=False                     \n",
    "    )\n",
    "\n",
    "    signals_files = []\n",
    "    \n",
    "    for f in signals_files_sorted:\n",
    "        signals_files.append(f.name)\n",
    "\n",
    "    signals_files = [f for f in signals_files if f != '.ipynb_checkpoints']\n",
    "    \n",
    "    for data_file,signal_file in zip(data_files,signals_files):\n",
    "\n",
    "        # Load the match trades tick data\n",
    "        with open(\"Data/\"+data_file) as f:\n",
    "            MatchTrades_tickdata = (pd.read_json(f)[[\"timestamp\",\"qty\",\"price\"]]).astype({\"qty\":\"float32\",\"price\":\"float64\"})\n",
    "            MatchTrades_tickdata[\"timestamp\"] = pd.to_datetime(MatchTrades_tickdata[\"timestamp\"], unit='ms')\n",
    "\n",
    "        # print(MatchTrades_tickdata)\n",
    "        \n",
    "        # load the signal data\n",
    "        with open(\"Signals/\"+f\"{folder} Signals/\"+signal_file) as f:\n",
    "            signal_df = pd.read_json(f).astype({\"Signal SMA\":\"int16\",\"Signal EMA\":\"int16\",\"Signal RSI\":\"int16\"})\n",
    "            signal_df[\"timestamp\"] = pd.to_datetime(signal_df['timestamp'], unit='ms')\n",
    "\n",
    "        # print(signal_df)\n",
    "\n",
    "        bartype = folder\n",
    "        signals = signal_df.iloc[:,[0,10,11,12]]\n",
    "        stats_data = signal_df.iloc[:,:10]\n",
    "        MatchTrades_tickdata = MatchTrades_tickdata\n",
    "        complementary_stats = [\"ATR\"]\n",
    "    \n",
    "        LabellingProcess = Labelling_Process(bartype,stats_data,signals,complementary_stats,MatchTrades_tickdata,parallel_processing=True)\n",
    "\n",
    "        if results == []:\n",
    "            for signal in LabellingProcess.return_results():\n",
    "                signal_results = (LabellingProcess.return_results()[signal])[\"total_positions\"]\n",
    "                results.append({\"signal\":signal,\"total_positions\":signal_results})\n",
    "        \n",
    "        else:        \n",
    "            for signal,index in zip(LabellingProcess.return_results(),range(0,len(LabellingProcess.return_results()))):\n",
    "                signal_results = (LabellingProcess.return_results()[signal])[\"total_positions\"]\n",
    "                ((results[index])[\"total_positions\"]) = pd.concat([(results[index])[\"total_positions\"],signal_results])\n",
    "                \n",
    "    for positions in results:\n",
    "        raw_data = positions[\"total_positions\"].to_dict(orient=\"records\")\n",
    "        json_raw_data = json_util.dumps(raw_data)\n",
    "        signal = positions[\"signal\"]\n",
    "        \n",
    "        with open(f\"Positions/{folder}/{signal}.json\", \"w\") as f:\n",
    "                f.write(json_raw_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
